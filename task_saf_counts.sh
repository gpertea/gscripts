#!/bin/bash

#SBATCH --job-name=fc_read_count
#SBATCH --output=logs/fc_count_%A_%a.out # Log file for stdout (%A=jobID, %a=taskID)
#SBATCH --error=logs/fc_count_%A_%a.err  # Log file for stderr
#SBATCH --qos=shared-200-2
#SBATCH --nodes=1                        # We need only one node per task
#SBATCH --ntasks=1                       # One task (process) per node
#SBATCH --cpus-per-task=4                # Request CPUs (2 for view, 2 for sort, 2 for fc?)
#SBATCH --mem=16G                        # Request memory (samtools sort needs memory!)
#SBATCH --time=01:00:00                  # Max walltime (adjust per file)

# --- Job Configuration ---
SAF_ANNOTATION="intervals.saf"            # Path to your annotation in SAF format
BED="intervals.bed"
CRAM_LIST_FILE="cram_files.list"          # Master list of CRAM files (one full path per line)
BASE_OUTPUT_DIR="fcounts" # Directory to store results from each task
FINAL_MATRIX="exon_read_counts_all.tsv" # Final combined output file name (for instructions)
CRAM_REF=/dcs04/lieber/lcolladotor/chessBrain_LIBD4085/ref/hg38mod_noPARs.fa


# --- Tool Settings ---
# Flags to FILTER OUT reads: Unmapped(4), Secondary(256), Supplementary(2048), QCfail(512) = 2820
EXCLUDE_FLAGS=2820
# Flags to REQUIRE: Paired(1).
REQUIRE_FLAGS=1
VIEW_THREADS=2
SORT_THREADS=2
FC_THREADS=2 # featureCounts threads for processing
SORT_MEM_PER_THREAD="4G" # Memory per thread for samtools sort

# --- Sanity Checks ---
if [ ! -f "$SAF_ANNOTATION" ]; then echo "Error: SAF file not found: $SAF_ANNOTATION"; exit 1; fi
if ! command -v samtools &> /dev/null; then echo "Error: samtools not found."; exit 1; fi
if ! command -v featureCounts &> /dev/null; then echo "Error: featureCounts (subread package) not found."; exit 1; fi

# --- SLURM Array Task Logic ---
TASK_ID=${SLURM_ARRAY_TASK_ID}
echo "Running SLURM Task $TASK_ID"

# Get the CRAM file for this task
CRAM_FILE=$(sed -n "${TASK_ID}p" "$CRAM_LIST_FILE")
if [ -z "$CRAM_FILE" ] || [ ! -f "$CRAM_FILE" ]; then
    echo "Error: CRAM file not found or invalid for task $TASK_ID (line $TASK_ID of $CRAM_LIST_FILE): $CRAM_FILE"
    exit 1
fi

# Extract sample name (R* format)
SAMPLE_NAME=$(basename "$(dirname "$CRAM_FILE")")
echo "Processing Sample: $SAMPLE_NAME, File: $CRAM_FILE"

# --- Output File Paths ---
mkdir -p "$BASE_OUTPUT_DIR"
# featureCounts output - contains counts and summary info
FC_OUTPUT="${BASE_OUTPUT_DIR}/${SAMPLE_NAME}.counts.tsv"
# Summary file automatically generated by featureCounts
FC_SUMMARY="${BASE_OUTPUT_DIR}/${SAMPLE_NAME}.counts.tsv.summary"

# Check if final output for this sample already exists
if [ -f "$FC_OUTPUT" ] && [ -f "$FC_SUMMARY" ]; then
    echo "Skipping $SAMPLE_NAME, output files already exist: $FC_OUTPUT"
    exit 0
fi

echo "Running samtools view | samtools sort | featureCounts (strandedness -s 2) for $SAMPLE_NAME..."

# --- Core Pipeline ---
samtools view -u -@ "$VIEW_THREADS" -L $BED -f "$REQUIRE_FLAGS" -F "$EXCLUDE_FLAGS" -T "$CRAM_REF" "$CRAM_FILE" \
    | samtools sort -O sam -n -@ "$SORT_THREADS" -m "$SORT_MEM_PER_THREAD" - \
    | featureCounts -p -s 2 -T "$FC_THREADS" -F SAF -a "$SAF_ANNOTATION" \
        -o "$FC_OUTPUT" 

# --- Check Exit Status ---
# Check the exit status of featureCounts (last command in the pipe)
status=${PIPESTATUS[2]}
if [ $status -ne 0 ]; then
    echo "Error running featureCounts pipeline for $SAMPLE_NAME (featureCounts exit status: $status)."
    # Clean up potentially incomplete output files
    rm -f "$FC_OUTPUT" "$FC_SUMMARY"
    exit 1
else
    echo "featureCounts pipeline completed successfully for $SAMPLE_NAME."
    echo "Output counts: $FC_OUTPUT"
    echo "Output summary: $FC_SUMMARY"
fi

echo "Task $TASK_ID finished."

